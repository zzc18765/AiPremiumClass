{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 周三任务\n",
    "1. 使用pytorch搭建神经网络模型，实现对KMNIST数据集的训练。\n",
    "https://pytorch.org/vision/stable/generated/torchvision.datasets.KMNIST.html#torchvision.datasets.KMNIST\n",
    "2. 尝试调整模型结构（变更神经元数量，增加隐藏层）来提升模型预测的准确率\n",
    "3. 调试超参数，观察学习率和批次大小对训练的影响。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.使用KMnist数据集 训练神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms.v2 import ToTensor     # 转换图像数据为张量\n",
    "from torchvision.datasets import KMNIST\n",
    "from torch.utils.data import DataLoader  # 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数（LR：学习率 、epochs:训练次数、BATCH_SIZE：一次？数据）\n",
    "LR = 1e-3\n",
    "epochs = 150\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\transforms\\v2\\_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n",
      "  6%|▌         | 1.11M/18.2M [00:53<13:39, 20.8kB/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 数据集加载\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mKMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m test_data \u001b[38;5;241m=\u001b[39m KMNIST(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m                          transform\u001b[38;5;241m=\u001b[39mToTensor())\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:100\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:188\u001b[0m, in \u001b[0;36mMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    186\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmirror\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    190\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend(e)\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\datasets\\utils.py:391\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    389\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 391\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    393\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    394\u001b[0m extract_archive(archive, extract_root, remove_finished)\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\datasets\\utils.py:130\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# download the file\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\site-packages\\torchvision\\datasets\\utils.py:30\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m chunk \u001b[38;5;241m:=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     31\u001b[0m             fh\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[0;32m     32\u001b[0m             pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\python_env\\miniconda3\\envs\\py312\\Lib\\ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 数据集加载\n",
    "train_data = KMNIST(root='./data', train=True, download=True, \n",
    "                          transform=ToTensor())\n",
    "test_data = KMNIST(root='./data', train=False, download=True,\n",
    "                         transform=ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHo1JREFUeJzt3XtwVPX9xvFnCWRFTZaGkJtcDKDSEcERJc2oiJICKaOA1IJaB6zFosER8FbaKtraicUZtFq81Q7oaNDSERBnitUoodgAA0IpVpGksWAhAZmyC4GESL6/P/iZukKA77KbTy7v18x3huyeJ+fj8ZjHs7ucBJxzTgAAtLBO1gMAADomCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICWsCUKVMUCASaXf/5z3+sRwRaXIB7wQGJV15ersrKyqjHnHOaNm2azj33XH300UdGkwF2OlsPAHQE+fn5ys/Pj3ps9erVOnjwoG6++WajqQBbvAQHGCkpKVEgENBNN91kPQpggpfgAAMNDQ3Kzs7WgAEDtHr1autxABNcAQEG3n77be3du5eX39ChUUCAgZKSEnXp0kU/+MEPrEcBzPASHNDCDhw4oMzMTF1zzTVavny59TiAGa6AgBa2dOlSPv0GiCsgoMUVFhZq9erVqqmp0Zlnnmk9DmCGKyCgBe3Zs0fvvvuuxo8fT/mgw6OAgBb0+uuv68svv+TlN0C8BAe0qPz8fP3rX//Szp07lZSUZD0OYIoCAgCY4CU4AIAJCggAYIICAgCYoIAAACYoIACACQoIAGCi1f1G1MbGRu3cuVMpKSkKBALW4wAAPDnntH//fuXk5KhTp+avc1pdAe3cuVO9evWyHgMAcJp27Nihnj17Nvt8q3sJLiUlxXoEAEAcnOznecIKaP78+Tr33HN1xhlnKC8vT+vWrTulHC+7AUD7cLKf5wkpoNdff12zZs3SnDlz9OGHH2rw4MEaNWqUdu/enYjdAQDaIpcAQ4cOdUVFRU1fHzlyxOXk5Lji4uKTZsPhsJPEYrFYrDa+wuHwCX/ex/0K6PDhw9qwYYMKCgqaHuvUqZMKCgpUXl5+zPb19fWKRCJRCwDQ/sW9gL744gsdOXJEmZmZUY9nZmaqurr6mO2Li4sVCoWaFp+AA4COwfxTcLNnz1Y4HG5aO3bssB4JANAC4v73gNLT05WUlKSampqox2tqapSVlXXM9sFgUMFgMN5jAABaubhfASUnJ2vIkCEqLS1teqyxsVGlpaXKz8+P9+4AAG1UQu6EMGvWLE2ePFmXXnqphg4dqieffFK1tbW69dZbE7E7AEAblJACmjhxovbs2aOHHnpI1dXVuvjii7VixYpjPpgAAOi4As45Zz3E10UiEYVCIesxAACnKRwOKzU1tdnnzT8FBwDomCggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGAi7gX08MMPKxAIRK0BAwbEezcAgDaucyK+6YUXXqh33333fzvpnJDdAADasIQ0Q+fOnZWVlZWIbw0AaCcS8h7Qtm3blJOTo759++rmm2/W9u3bm922vr5ekUgkagEA2r+4F1BeXp4WLlyoFStW6Nlnn1VVVZWuvPJK7d+//7jbFxcXKxQKNa1evXrFeyQAQCsUcM65RO5g37596tOnj+bNm6fbbrvtmOfr6+tVX1/f9HUkEqGEAKAdCIfDSk1Nbfb5hH86oFu3bjr//PNVUVFx3OeDwaCCwWCixwAAtDIJ/3tABw4cUGVlpbKzsxO9KwBAGxL3Arr33ntVVlamzz77TH/72980fvx4JSUl6cYbb4z3rgAAbVjcX4L7/PPPdeONN2rv3r3q0aOHrrjiCq1Zs0Y9evSI964AAG1Ywj+E4CsSiSgUClmPgQ4qEAh4Z3796197Z3r27Omd+fqHdU7V/PnzvTOStGnTJu/MVVdd5Z3JycnxzixatMg7Axsn+xAC94IDAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgIuG/kA6wEOsvOZw5c6Z35oEHHvDOHDlyxDtTXFzsnYnlpqKxKisra7F9oX3gCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIK7YaNdGjlyZEy5Rx991DvT2Njonfn+97/vnXnzzTe9M0BrxhUQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAE9yMFC2qc2f/U+4nP/lJi2Qkqba21jvz2GOPeWfy8vK8M6tWrfLO7Nu3zzsDtBSugAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJjgZqSIWSw3Fn3iiSe8M0VFRd6ZWG4qKkl1dXXembvuuss7k52d7Z3p0qWLd+bxxx/3zkjSnj17YsoBPrgCAgCYoIAAACa8C2jVqlW69tprlZOTo0AgoKVLl0Y975zTQw89pOzsbHXt2lUFBQXatm1bvOYFALQT3gVUW1urwYMHa/78+cd9fu7cuXrqqaf03HPPae3atTrrrLM0atSomF5bBwC0X97vIhcWFqqwsPC4zznn9OSTT+oXv/iFxo4dK0l6+eWXlZmZqaVLl2rSpEmnNy0AoN2I63tAVVVVqq6uVkFBQdNjoVBIeXl5Ki8vP26mvr5ekUgkagEA2r+4FlB1dbUkKTMzM+rxzMzMpue+qbi4WKFQqGn16tUrniMBAFop80/BzZ49W+FwuGnt2LHDeiQAQAuIawFlZWVJkmpqaqIer6mpaXrum4LBoFJTU6MWAKD9i2sB5ebmKisrS6WlpU2PRSIRrV27Vvn5+fHcFQCgjfP+FNyBAwdUUVHR9HVVVZU2bdqktLQ09e7dWzNmzNCjjz6q8847T7m5uXrwwQeVk5OjcePGxXNuAEAb511A69ev19VXX9309axZsyRJkydP1sKFC3X//fertrZWt99+u/bt26crrrhCK1as0BlnnBG/qQEAbV7AOeesh/i6SCSiUChkPUaHMn78+JhyP/rRj7wzY8aM8c589NFH3plYbvYpSd27d/fOxHKnj/POO887E4vf/va3MeVmzJgR30HQIYXD4RO+r2/+KTgAQMdEAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDB3bDbmVtuucU78+KLL8a0r+TkZO/M3//+d+/Mj3/8Y+/M138poo8bbrjBO7N69WrvzMaNG70z559/vndm9+7d3hlJGjt2rHcmlv9uBw0a5J3p27evd+bjjz/2zkixna/r1q3zzhw6dMg70xZwN2wAQKtEAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADARGfrATqKlJQU78wrr7zinbnyyiu9M506xfb/IbNnz/bO/P73v/fOXHfddd6Zmpoa74wknXXWWd6ZH/7wh96Z/v37e2dikZGREVMulhusJiUlxbSv1iyWezV/8skn3plnnnnGO/P88897ZySpoaEhplwicAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADARMDFcre9BIpEIgqFQtZjnFBycrJ3ZuHChd6ZG2+80TuzYcMG70xxcbF3RpKGDh3qnYnlxp05OTnemVjF8p/DZ5995p0555xzvDOxnHexKisr88689tpr3plevXp5Zy699FLvzMiRI70zrV1VVVVMuZ/+9KfemT/96U9e2zvn5JxTOBxWampqs9txBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMBEZ+sBLF199dUx5V544QXvTO/evb0zn376qXdm6dKl3plnnnnGOyNJPXr08M4EAoGY9uVr27ZtMeVi+Xc7b94878ydd97pnXn66ae9M7F64403vDPPPfdcAiY5Vizn0He/+92Y9pWUlOSdmTFjhncmlhus5ubmemckqaSkxDuzZ88er+2//PJL/fWvfz3pdlwBAQBMUEAAABPeBbRq1Spde+21ysnJUSAQOOYlnylTpigQCESt0aNHx2teAEA74V1AtbW1Gjx4sObPn9/sNqNHj9auXbua1qJFi05rSABA++P9IYTCwkIVFhaecJtgMKisrKyYhwIAtH8JeQ9o5cqVysjI0AUXXKA77rhDe/fubXbb+vp6RSKRqAUAaP/iXkCjR4/Wyy+/rNLSUv3mN79RWVmZCgsLdeTIkeNuX1xcrFAo1LRi+R3xAIC2J+5/D2jSpElNf77ooos0aNAg9evXTytXrtSIESOO2X727NmaNWtW09eRSIQSAoAOIOEfw+7bt6/S09NVUVFx3OeDwaBSU1OjFgCg/Ut4AX3++efau3evsrOzE70rAEAb4v0S3IEDB6KuZqqqqrRp0yalpaUpLS1NjzzyiCZMmKCsrCxVVlbq/vvvV//+/TVq1Ki4Dg4AaNu8C2j9+vVR91D76v2byZMn69lnn9XmzZv10ksvad++fcrJydHIkSP1q1/9SsFgMH5TAwDaPO8CGj58uJxzzT7/9ttvn9ZAX+dz08EpU6Z4f/97773XOyNJdXV13pktW7Z4Zy655BLvzD333OOdaWxs9M7EmovlLyU3NDR4Z7p37+6dkY7+D5avWI5Dly5dvDOxaO7Tpyfzj3/8I86TxM+Jfv405y9/+UsCJjm+P//5z96ZoqIi78zvfvc774wU2w1Wx4wZ47V9XV0dNyMFALReFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADBBAQEATFBAAAATcf+V3PEyatQorzsGz5s3z3sfsd4pONY7LbeEQ4cOeWdKS0tj2ldJSYl3Jpa7paenp3tnFi9e7J2RpOXLl3tnfv7zn3tnevTo4Z2JxaeffhpT7oMPPojzJG1T//79vTMPPPCAd2bSpEnemZY0ZMgQr+1ra2tPaTuugAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJhotTcjvfDCCxUMBk95+27duiVuGCOVlZXemalTp3pnVq9e7Z2RpIaGhphyvnbv3u2dueWWW2La1wsvvOCdieVGuP/973+9M7F48sknY8odPnw4voPEUa9evbwzd999d0z7uvXWW70zaWlpMe2rNXvzzTe9tq+vrz+l7bgCAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYCLgnHPWQ3xdJBJRKBRSUlKSAoHAKedGjBjhva9rrrnGOyNJF198sXemoqLCO/P44497Zz777DPvDP7n7LPP9s68+uqr3pnrrrvOOxOLRx99NKbcmjVrvDP9+vXzztxwww3emVj++4vl32t7tW7dOu+M789X55xqa2sVDoeVmpra7HZcAQEATFBAAAATFBAAwAQFBAAwQQEBAExQQAAAExQQAMAEBQQAMEEBAQBMUEAAABMUEADABAUEADDRam9GCrQVaWlp3pm8vDzvTLdu3bwz1dXV3hlJmjhxondmzJgx3pmePXt6Z9qjjRs3emdeeumlmPb14osvemdqa2tj2hc3IwUAtEoUEADAhFcBFRcX67LLLlNKSooyMjI0btw4bd26NWqburo6FRUVqXv37jr77LM1YcIE1dTUxHVoAEDb51VAZWVlKioq0po1a/TOO++ooaFBI0eOjHp9cObMmVq+fLkWL16ssrIy7dy5U9dff33cBwcAtG2dfTZesWJF1NcLFy5URkaGNmzYoGHDhikcDusPf/iDSkpKmn7b6IIFC/Ttb39ba9as0Xe+8534TQ4AaNNO6z2gcDgs6X+fAtqwYYMaGhpUUFDQtM2AAQPUu3dvlZeXH/d71NfXKxKJRC0AQPsXcwE1NjZqxowZuvzyyzVw4EBJRz/ymZycfMzHRTMzM5v9OGhxcbFCoVDT6tWrV6wjAQDakJgLqKioSFu2bNFrr712WgPMnj1b4XC4ae3YseO0vh8AoG3weg/oK9OnT9dbb72lVatWRf1FsqysLB0+fFj79u2LugqqqalRVlbWcb9XMBhUMBiMZQwAQBvmdQXknNP06dO1ZMkSvffee8rNzY16fsiQIerSpYtKS0ubHtu6dau2b9+u/Pz8+EwMAGgXvK6AioqKVFJSomXLliklJaXpfZ1QKKSuXbsqFArptttu06xZs5SWlqbU1FTdddddys/P5xNwAIAoXgX07LPPSpKGDx8e9fiCBQs0ZcoUSdITTzyhTp06acKECaqvr9eoUaP0zDPPxGVYAED7wc1IgdN09dVXe2fef//9BEyC5vTt2zem3IlupNmcjz76yDvz5Zdfemda2Y/u4+JmpACAVokCAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIK7YQMAEoK7YQMAWiUKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJrwIqLi7WZZddppSUFGVkZGjcuHHaunVr1DbDhw9XIBCIWtOmTYvr0ACAts+rgMrKylRUVKQ1a9bonXfeUUNDg0aOHKna2tqo7aZOnapdu3Y1rblz58Z1aABA29fZZ+MVK1ZEfb1w4UJlZGRow4YNGjZsWNPjZ555prKysuIzIQCgXTqt94DC4bAkKS0tLerxV199Venp6Ro4cKBmz56tgwcPNvs96uvrFYlEohYAoANwMTpy5IgbM2aMu/zyy6Mef/75592KFSvc5s2b3SuvvOLOOeccN378+Ga/z5w5c5wkFovFYrWzFQ6HT9gjMRfQtGnTXJ8+fdyOHTtOuF1paamT5CoqKo77fF1dnQuHw01rx44d5geNxWKxWKe/TlZAXu8BfWX69Ol66623tGrVKvXs2fOE2+bl5UmSKioq1K9fv2OeDwaDCgaDsYwBAGjDvArIOae77rpLS5Ys0cqVK5Wbm3vSzKZNmyRJ2dnZMQ0IAGifvAqoqKhIJSUlWrZsmVJSUlRdXS1JCoVC6tq1qyorK1VSUqLvfe976t69uzZv3qyZM2dq2LBhGjRoUEL+AQAAbZTP+z5q5nW+BQsWOOec2759uxs2bJhLS0tzwWDQ9e/f3913330nfR3w68LhsPnrliwWi8U6/XWyn/2B/y+WViMSiSgUClmPAQA4TeFwWKmpqc0+z73gAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAIAJCggAYIICAgCYoIAAACYoIACACQoIAGCCAgIAmKCAAAAmWl0BOeesRwAAxMHJfp63ugLav3+/9QgAgDg42c/zgGtllxyNjY3auXOnUlJSFAgEop6LRCLq1auXduzYodTUVKMJ7XEcjuI4HMVxOIrjcFRrOA7OOe3fv185OTnq1Kn565zOLTjTKenUqZN69ux5wm1SU1M79An2FY7DURyHozgOR3EcjrI+DqFQ6KTbtLqX4AAAHQMFBAAw0aYKKBgMas6cOQoGg9ajmOI4HMVxOIrjcBTH4ai2dBxa3YcQAAAdQ5u6AgIAtB8UEADABAUEADBBAQEATFBAAAATbaaA5s+fr3PPPVdnnHGG8vLytG7dOuuRWtzDDz+sQCAQtQYMGGA9VsKtWrVK1157rXJychQIBLR06dKo551zeuihh5Sdna2uXbuqoKBA27Ztsxk2gU52HKZMmXLM+TF69GibYROkuLhYl112mVJSUpSRkaFx48Zp69atUdvU1dWpqKhI3bt319lnn60JEyaopqbGaOLEOJXjMHz48GPOh2nTphlNfHxtooBef/11zZo1S3PmzNGHH36owYMHa9SoUdq9e7f1aC3uwgsv1K5du5rW6tWrrUdKuNraWg0ePFjz588/7vNz587VU089peeee05r167VWWedpVGjRqmurq6FJ02skx0HSRo9enTU+bFo0aIWnDDxysrKVFRUpDVr1uidd95RQ0ODRo4cqdra2qZtZs6cqeXLl2vx4sUqKyvTzp07df311xtOHX+nchwkaerUqVHnw9y5c40mboZrA4YOHeqKioqavj5y5IjLyclxxcXFhlO1vDlz5rjBgwdbj2FKkluyZEnT142NjS4rK8s9/vjjTY/t27fPBYNBt2jRIoMJW8Y3j4Nzzk2ePNmNHTvWZB4ru3fvdpJcWVmZc+7ov/suXbq4xYsXN23z8ccfO0muvLzcasyE++ZxcM65q666yt199912Q52CVn8FdPjwYW3YsEEFBQVNj3Xq1EkFBQUqLy83nMzGtm3blJOTo759++rmm2/W9u3brUcyVVVVperq6qjzIxQKKS8vr0OeHytXrlRGRoYuuOAC3XHHHdq7d6/1SAkVDoclSWlpaZKkDRs2qKGhIep8GDBggHr37t2uz4dvHoevvPrqq0pPT9fAgQM1e/ZsHTx40GK8ZrW6u2F/0xdffKEjR44oMzMz6vHMzEx98sknRlPZyMvL08KFC3XBBRdo165deuSRR3TllVdqy5YtSklJsR7PRHV1tSQd9/z46rmOYvTo0br++uuVm5uryspK/exnP1NhYaHKy8uVlJRkPV7cNTY2asaMGbr88ss1cOBASUfPh+TkZHXr1i1q2/Z8PhzvOEjSTTfdpD59+ignJ0ebN2/WAw88oK1bt+qNN94wnDZaqy8g/E9hYWHTnwcNGqS8vDz16dNHf/zjH3XbbbcZTobWYNKkSU1/vuiiizRo0CD169dPK1eu1IgRIwwnS4yioiJt2bKlQ7wPeiLNHYfbb7+96c8XXXSRsrOzNWLECFVWVqpfv34tPeZxtfqX4NLT05WUlHTMp1hqamqUlZVlNFXr0K1bN51//vmqqKiwHsXMV+cA58ex+vbtq/T09HZ5fkyfPl1vvfWW3n///ajfH5aVlaXDhw9r3759Udu31/OhueNwPHl5eZLUqs6HVl9AycnJGjJkiEpLS5sea2xsVGlpqfLz8w0ns3fgwAFVVlYqOzvbehQzubm5ysrKijo/IpGI1q5d2+HPj88//1x79+5tV+eHc07Tp0/XkiVL9N577yk3Nzfq+SFDhqhLly5R58PWrVu1ffv2dnU+nOw4HM+mTZskqXWdD9afgjgVr732mgsGg27hwoXun//8p7v99ttdt27dXHV1tfVoLeqee+5xK1eudFVVVe6DDz5wBQUFLj093e3evdt6tITav3+/27hxo9u4caOT5ObNm+c2btzo/v3vfzvnnHvsscdct27d3LJly9zmzZvd2LFjXW5urjt06JDx5PF1ouOwf/9+d++997ry8nJXVVXl3n33XXfJJZe48847z9XV1VmPHjd33HGHC4VCbuXKlW7Xrl1N6+DBg03bTJs2zfXu3du99957bv369S4/P9/l5+cbTh1/JzsOFRUV7pe//KVbv369q6qqcsuWLXN9+/Z1w4YNM548WpsoIOece/rpp13v3r1dcnKyGzp0qFuzZo31SC1u4sSJLjs72yUnJ7tzzjnHTZw40VVUVFiPlXDvv/++k3TMmjx5snPu6EexH3zwQZeZmemCwaAbMWKE27p1q+3QCXCi43Dw4EE3cuRI16NHD9elSxfXp08fN3Xq1Hb3P2nH++eX5BYsWNC0zaFDh9ydd97pvvWtb7kzzzzTjR8/3u3atctu6AQ42XHYvn27GzZsmEtLS3PBYND179/f3XfffS4cDtsO/g38PiAAgIlW/x4QAKB9ooAAACYoIACACQoIAGCCAgIAmKCAAAAmKCAAgAkKCABgggICAJiggAAAJiggAICJ/wMhPcCvAgaPzgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img,label = train_data[1]\n",
    "img.numpy().shape\n",
    "#去除图片的单通道， 使用图片的尺寸\n",
    "plt.imshow(img.numpy().squeeze(), cmap='gray')\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trian_dl = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)  # shuffle=True表示打乱数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(256, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数&优化器\n",
    "loss_fn = nn.CrossEntropyLoss()  # 交叉熵损失函数\n",
    "# 优化器（模型参数更新）\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为什么要清除梯度，再更新参数？\n",
    "因为梯度是内部运算存储的，不清除会累加，导致步长过大，可能无法很好的收敛函数，每次更新参数后，需要清除梯度，否则会影响下一次的更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 Loss: 2.2949724197387695\n",
      "Epoch:1 Loss: 2.2827203273773193\n",
      "Epoch:2 Loss: 2.2614500522613525\n",
      "Epoch:3 Loss: 2.260878562927246\n",
      "Epoch:4 Loss: 2.2431552410125732\n",
      "Epoch:5 Loss: 2.2188303470611572\n",
      "Epoch:6 Loss: 2.2028350830078125\n",
      "Epoch:7 Loss: 2.1891868114471436\n",
      "Epoch:8 Loss: 2.174729585647583\n",
      "Epoch:9 Loss: 2.1593434810638428\n",
      "Epoch:10 Loss: 2.156759023666382\n",
      "Epoch:11 Loss: 2.1055524349212646\n",
      "Epoch:12 Loss: 2.101066827774048\n",
      "Epoch:13 Loss: 2.0667498111724854\n",
      "Epoch:14 Loss: 2.0761470794677734\n",
      "Epoch:15 Loss: 2.0078113079071045\n",
      "Epoch:16 Loss: 1.9736117124557495\n",
      "Epoch:17 Loss: 2.000061273574829\n",
      "Epoch:18 Loss: 1.9550198316574097\n",
      "Epoch:19 Loss: 1.9544330835342407\n",
      "Epoch:20 Loss: 1.9359760284423828\n",
      "Epoch:21 Loss: 1.8944798707962036\n",
      "Epoch:22 Loss: 1.8442035913467407\n",
      "Epoch:23 Loss: 1.8258461952209473\n",
      "Epoch:24 Loss: 1.78997004032135\n",
      "Epoch:25 Loss: 1.7949461936950684\n",
      "Epoch:26 Loss: 1.699066162109375\n",
      "Epoch:27 Loss: 1.7932456731796265\n",
      "Epoch:28 Loss: 1.6598411798477173\n",
      "Epoch:29 Loss: 1.6636499166488647\n",
      "Epoch:30 Loss: 1.6115881204605103\n",
      "Epoch:31 Loss: 1.56694757938385\n",
      "Epoch:32 Loss: 1.604077696800232\n",
      "Epoch:33 Loss: 1.6042275428771973\n",
      "Epoch:34 Loss: 1.646527886390686\n",
      "Epoch:35 Loss: 1.526955246925354\n",
      "Epoch:36 Loss: 1.5504854917526245\n",
      "Epoch:37 Loss: 1.3827462196350098\n",
      "Epoch:38 Loss: 1.4874471426010132\n",
      "Epoch:39 Loss: 1.3638581037521362\n",
      "Epoch:40 Loss: 1.391299843788147\n",
      "Epoch:41 Loss: 1.4950895309448242\n",
      "Epoch:42 Loss: 1.4103885889053345\n",
      "Epoch:43 Loss: 1.3887909650802612\n",
      "Epoch:44 Loss: 1.452225685119629\n",
      "Epoch:45 Loss: 1.3004589080810547\n",
      "Epoch:46 Loss: 1.5329245328903198\n",
      "Epoch:47 Loss: 1.2979401350021362\n",
      "Epoch:48 Loss: 1.2866450548171997\n",
      "Epoch:49 Loss: 1.3064695596694946\n",
      "Epoch:50 Loss: 1.2293647527694702\n",
      "Epoch:51 Loss: 1.1685190200805664\n",
      "Epoch:52 Loss: 1.267316222190857\n",
      "Epoch:53 Loss: 1.2529525756835938\n",
      "Epoch:54 Loss: 1.361549973487854\n",
      "Epoch:55 Loss: 1.1214543581008911\n",
      "Epoch:56 Loss: 1.2188721895217896\n",
      "Epoch:57 Loss: 1.0932570695877075\n",
      "Epoch:58 Loss: 1.1105412244796753\n",
      "Epoch:59 Loss: 1.0570625066757202\n",
      "Epoch:60 Loss: 1.0443674325942993\n",
      "Epoch:61 Loss: 0.9773818850517273\n",
      "Epoch:62 Loss: 1.081383228302002\n",
      "Epoch:63 Loss: 1.0315735340118408\n",
      "Epoch:64 Loss: 1.1309419870376587\n",
      "Epoch:65 Loss: 1.0598737001419067\n",
      "Epoch:66 Loss: 1.0908623933792114\n",
      "Epoch:67 Loss: 1.0776315927505493\n",
      "Epoch:68 Loss: 1.1484838724136353\n",
      "Epoch:69 Loss: 1.2718759775161743\n",
      "Epoch:70 Loss: 1.200432538986206\n",
      "Epoch:71 Loss: 1.0699368715286255\n",
      "Epoch:72 Loss: 1.0010303258895874\n",
      "Epoch:73 Loss: 1.01650869846344\n",
      "Epoch:74 Loss: 1.1278883218765259\n",
      "Epoch:75 Loss: 1.024191975593567\n",
      "Epoch:76 Loss: 0.933129608631134\n",
      "Epoch:77 Loss: 0.8572883605957031\n",
      "Epoch:78 Loss: 0.9602656364440918\n",
      "Epoch:79 Loss: 1.1982804536819458\n",
      "Epoch:80 Loss: 0.9088950753211975\n",
      "Epoch:81 Loss: 0.9147363305091858\n",
      "Epoch:82 Loss: 0.9885921478271484\n",
      "Epoch:83 Loss: 0.7632876038551331\n",
      "Epoch:84 Loss: 0.9802797436714172\n",
      "Epoch:85 Loss: 0.7925876975059509\n",
      "Epoch:86 Loss: 0.8812975287437439\n",
      "Epoch:87 Loss: 0.7615725994110107\n",
      "Epoch:88 Loss: 0.9247433543205261\n",
      "Epoch:89 Loss: 0.8360063433647156\n",
      "Epoch:90 Loss: 1.0887051820755005\n",
      "Epoch:91 Loss: 1.0187450647354126\n",
      "Epoch:92 Loss: 0.8700183033943176\n",
      "Epoch:93 Loss: 0.965263307094574\n",
      "Epoch:94 Loss: 0.9978761076927185\n",
      "Epoch:95 Loss: 0.8430783152580261\n",
      "Epoch:96 Loss: 0.8382557034492493\n",
      "Epoch:97 Loss: 1.0246039628982544\n",
      "Epoch:98 Loss: 0.9995048642158508\n",
      "Epoch:99 Loss: 0.9101569652557373\n",
      "Epoch:100 Loss: 0.8624143600463867\n",
      "Epoch:101 Loss: 0.8650316596031189\n",
      "Epoch:102 Loss: 0.7592236399650574\n",
      "Epoch:103 Loss: 0.8995092511177063\n",
      "Epoch:104 Loss: 0.7779060006141663\n",
      "Epoch:105 Loss: 0.7953377366065979\n",
      "Epoch:106 Loss: 0.7721405625343323\n",
      "Epoch:107 Loss: 0.9213677048683167\n",
      "Epoch:108 Loss: 0.7844934463500977\n",
      "Epoch:109 Loss: 0.8969842791557312\n",
      "Epoch:110 Loss: 0.7935298085212708\n",
      "Epoch:111 Loss: 0.7948945164680481\n",
      "Epoch:112 Loss: 0.8616451621055603\n",
      "Epoch:113 Loss: 1.0198619365692139\n",
      "Epoch:114 Loss: 0.780790388584137\n",
      "Epoch:115 Loss: 0.8231627941131592\n",
      "Epoch:116 Loss: 0.8635091185569763\n",
      "Epoch:117 Loss: 0.8554850220680237\n",
      "Epoch:118 Loss: 0.7845058441162109\n",
      "Epoch:119 Loss: 0.764507532119751\n",
      "Epoch:120 Loss: 0.6594322323799133\n",
      "Epoch:121 Loss: 0.8443564772605896\n",
      "Epoch:122 Loss: 0.7502710223197937\n",
      "Epoch:123 Loss: 1.006726861000061\n",
      "Epoch:124 Loss: 0.8739242553710938\n",
      "Epoch:125 Loss: 0.8800039887428284\n",
      "Epoch:126 Loss: 0.8859372138977051\n",
      "Epoch:127 Loss: 0.9232515692710876\n",
      "Epoch:128 Loss: 0.7724588513374329\n",
      "Epoch:129 Loss: 0.5929439067840576\n",
      "Epoch:130 Loss: 0.7831692099571228\n",
      "Epoch:131 Loss: 0.64969801902771\n",
      "Epoch:132 Loss: 0.6230625510215759\n",
      "Epoch:133 Loss: 0.6935809254646301\n",
      "Epoch:134 Loss: 0.8213734030723572\n",
      "Epoch:135 Loss: 0.7291770577430725\n",
      "Epoch:136 Loss: 0.8974499702453613\n",
      "Epoch:137 Loss: 0.8564558625221252\n",
      "Epoch:138 Loss: 0.6970863342285156\n",
      "Epoch:139 Loss: 0.6193056702613831\n",
      "Epoch:140 Loss: 0.7856078147888184\n",
      "Epoch:141 Loss: 0.803506076335907\n",
      "Epoch:142 Loss: 0.7513875961303711\n",
      "Epoch:143 Loss: 0.6916818618774414\n",
      "Epoch:144 Loss: 0.6612368226051331\n",
      "Epoch:145 Loss: 0.7338235378265381\n",
      "Epoch:146 Loss: 0.8190929889678955\n",
      "Epoch:147 Loss: 0.8044829368591309\n",
      "Epoch:148 Loss: 0.8402076363563538\n",
      "Epoch:149 Loss: 0.7668378353118896\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 提取训练数据\n",
    "    for data, target in trian_dl:\n",
    "        # 前向运算\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        # 计算损失\n",
    "        loss = loss_fn(output, target)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # 所有参数梯度清零\n",
    "        loss.backward()     # 计算梯度（参数.grad）\n",
    "        optimizer.step()    # 更新参数\n",
    "\n",
    "    print(f'Epoch:{epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataLoader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 测试\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m test_dl \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m(test_data, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[0;32m      4\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DataLoader' is not defined"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "test_dl = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for data, target in test_dl:\n",
    "        output = model(data.reshape(-1, 784))\n",
    "        _, predicted = torch.max(output, 1)  # 返回每行最大值和索引\n",
    "        print(predicted)\n",
    "        total += target.size(0)  # size(0) 等效 shape[0]\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "print(f'Accuracy: {correct/total*100}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
